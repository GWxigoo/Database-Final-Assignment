# SQL Injection Detection Experiment

import time
import ast
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, roc_curve
)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

import tensorflow as tf
from tensorflow.keras import layers, Model

# Optional XGBoost
try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except:
    HAS_XGB = False

#Input file path
INPUT_PATH = "/content/final final dataset.xlsx"
LABEL_COL = "Label"
TEXT_COL = "filtered_tokens"

RULE_FEATURES = [
    "query_len","is_boolean","always_true","is_union","is_comment",
    "is_time_based","comparison_op_count","parentheses_depth",
    "logic_operator_count","str_count","num_count"
]

N_SPLITS = 5
RANDOM_STATE = 42

# Dataset Loading

def load_dataset(path):
    df = pd.read_excel(path)

    df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors="coerce")
    df = df.dropna(subset=[LABEL_COL])
    df[LABEL_COL] = df[LABEL_COL].astype(int)

    for c in RULE_FEATURES:
        df[c] = pd.to_numeric(df[c], errors="coerce").replace([np.inf, -np.inf], 0).fillna(0)

    def tokens_to_text(x):
        if isinstance(x, list):
            return " ".join(map(str, x))
        try:
            v = ast.literal_eval(str(x))
            if isinstance(v, list):
                return " ".join(map(str, v))
        except:
            pass
        return str(x)

    df[TEXT_COL] = df[TEXT_COL].apply(tokens_to_text)
    return df

# Evaluation Metrics

def compute_metrics(y_true, y_pred, scores):
    return {
        "acc": accuracy_score(y_true, y_pred),
        "prec": precision_score(y_true, y_pred, zero_division=0),
        "rec": recall_score(y_true, y_pred, zero_division=0),
        "f1": f1_score(y_true, y_pred, zero_division=0),
        "auc": roc_auc_score(y_true, scores),
        "cm": confusion_matrix(y_true, y_pred)
    }

#Lightweight 1D-CNN

def build_hybrid_model(vocab_size, num_features):
    text_input = layers.Input(shape=(30,))
    x = layers.Embedding(vocab_size, 32)(text_input)
    x = layers.Conv1D(32, 3, activation="relu", padding="same")(x)
    x = layers.MaxPooling1D(2)(x)
    x = layers.LSTM(16)(x)
    x = layers.Dropout(0.2)(x)

    feat_input = layers.Input(shape=(num_features,))
    f = layers.Dense(16, activation="relu")(feat_input)

    z = layers.Concatenate()([x, f])
    z = layers.Dense(32, activation="relu")(z)
    out = layers.Dense(1, activation="sigmoid")(z)

    model = Model([text_input, feat_input], out)
    model.compile(
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=["accuracy", tf.keras.metrics.AUC(name="auc")]
    )
    return model

# Main

def main():
    df = load_dataset(INPUT_PATH)

    X_text = df[TEXT_COL].values
    X_feat = df[RULE_FEATURES].values.astype("float32")
    y = df[LABEL_COL].values

    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)

    results = {}
    roc_curves = {}

    # Logistic Regression
    start = time.time()
    metrics = []
    roc_curves["LR"] = []

    for tr, te in skf.split(X_text, y):
        vec = TfidfVectorizer(max_features=15000)
        Xtr = vec.fit_transform(X_text[tr])
        Xte = vec.transform(X_text[te])

        clf = LogisticRegression(max_iter=1000)
        clf.fit(Xtr, y[tr])

        scores = clf.predict_proba(Xte)[:, 1]
        preds = (scores >= 0.5).astype(int)

        metrics.append(compute_metrics(y[te], preds, scores))
        roc_curves["LR"].append(roc_curve(y[te], scores)[:2])

    results["LR + TF-IDF"] = (metrics, time.time() - start)

    # XGBoost
    if HAS_XGB:
        start = time.time()
        metrics = []
        roc_curves["XGB"] = []

        for tr, te in skf.split(X_text, y):
            vec = TfidfVectorizer(max_features=20000)
            Xtr = vec.fit_transform(X_text[tr])
            Xte = vec.transform(X_text[te])

            xgb = XGBClassifier(n_estimators=100, max_depth=4, eval_metric="logloss")
            xgb.fit(Xtr, y[tr])

            scores = xgb.predict_proba(Xte)[:, 1]
            preds = (scores >= 0.5).astype(int)

            metrics.append(compute_metrics(y[te], preds, scores))
            roc_curves["XGB"].append(roc_curve(y[te], scores)[:2])

        results["XGBoost + TF-IDF"] = (metrics, time.time() - start)

    # CNN–LSTM Hybrid
    start = time.time()
    metrics = []
    roc_curves["Hybrid"] = []

    for tr, te in skf.split(X_text, y):
        mu, sd = X_feat[tr].mean(0), X_feat[tr].std(0) + 1e-6
        Xtr_f = (X_feat[tr] - mu) / sd
        Xte_f = (X_feat[te] - mu) / sd

        vec = layers.TextVectorization(max_tokens=8000, output_mode="int", output_sequence_length=30)
        vec.adapt(X_text[tr])

        model = build_hybrid_model(len(vec.get_vocabulary()), Xtr_f.shape[1])
        model.fit([vec(X_text[tr]), Xtr_f], y[tr], epochs=3, batch_size=256, verbose=0)

        scores = model.predict([vec(X_text[te]), Xte_f]).ravel()
        preds = (scores >= 0.5).astype(int)

        metrics.append(compute_metrics(y[te], preds, scores))
        roc_curves["Hybrid"].append(roc_curve(y[te], scores)[:2])

    results["CNN–LSTM Hybrid"] = (metrics, time.time() - start)

    #  Result Summary Table
    summary = []
    for name, (ms, t) in results.items():
        summary.append({
            "Model": name,
            "Accuracy": np.mean([m["acc"] for m in ms]),
            "Precision": np.mean([m["prec"] for m in ms]),
            "Recall": np.mean([m["rec"] for m in ms]),
            "F1-score": np.mean([m["f1"] for m in ms]),
            "Runtime (s)": t
        })

    summary_df = pd.DataFrame(summary)
    print(summary_df)

    # Confusion Matrices
    for name, (ms, _) in results.items():
        cm = sum(m["cm"] for m in ms)
        plt.figure()
        plt.imshow(cm, cmap="Blues")
        plt.title(f"Confusion Matrix – {name}")
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        for i in range(2):
            for j in range(2):
                plt.text(j, i, cm[i, j], ha="center", va="center")
        plt.show()

    # ROC Curve

    plt.figure(figsize=(6, 5))

    for name, curves in roc_curves.items():
        mean_fpr = np.linspace(0, 1, 200)
        tprs = []
        aucs = []

        for fpr, tpr in curves:
            tprs.append(np.interp(mean_fpr, fpr, tpr))
            aucs.append(np.trapz(tpr, fpr))

        mean_tpr = np.mean(tprs, axis=0)
        mean_auc = np.mean(aucs)

        plt.plot(
            mean_fpr,
            mean_tpr,
            label=f"{name} (AUC = {mean_auc:.4f})"
        )

    plt.plot([0, 1], [0, 1], "--", color="gray")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curves (Mean over 5-fold CV)")
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.show()

    # Performance Bar Chart
    ax = summary_df.set_index("Model")[["Accuracy","Precision","Recall","F1-score"]] \
        .plot(kind="bar", figsize=(8, 5))

    ax.set_ylim(0, 1)
    ax.set_title("Model Performance Comparison")
    ax.set_ylabel("Score")

    ax.legend(
        loc="upper left",
        bbox_to_anchor=(1.02, 1),
        borderaxespad=0
    )

    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    main()
